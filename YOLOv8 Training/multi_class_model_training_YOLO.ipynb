{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import logging\n",
    "from typing import Dict, List, Set, Tuple  # Added Tuple here\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set GPU memory allocation to 80%\n",
    "torch.cuda.set_per_process_memory_fraction(0.8)\n",
    "\n",
    "def set_all_seeds(seed=42):\n",
    "    \"\"\"Set all random seeds for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def create_yaml_file(train_dir: str, \n",
    "                    val_dir: str, \n",
    "                    yaml_path: str, \n",
    "                    num_classes: int, \n",
    "                    class_names: List[str]):\n",
    "    \"\"\"\n",
    "    Create YAML configuration file for YOLOv8\n",
    "    Args:\n",
    "        train_dir: Path to training images directory\n",
    "        val_dir: Path to validation images directory\n",
    "        yaml_path: Output path for YAML file\n",
    "        num_classes: Number of classes\n",
    "        class_names: List of class names\n",
    "    \"\"\"\n",
    "    train_dir = os.path.abspath(train_dir)\n",
    "    val_dir = os.path.abspath(val_dir)\n",
    "    \n",
    "    yaml_content = {\n",
    "        'train': os.path.join(train_dir, 'images'),\n",
    "        'val': os.path.join(val_dir, 'images'),\n",
    "        'nc': num_classes,\n",
    "        'names': class_names\n",
    "    }\n",
    "    \n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(yaml_content, f)\n",
    "    \n",
    "    logging.info(f\"Created YAML configuration file at {yaml_path}\")\n",
    "\n",
    "def get_background_images(train_image_count: int, \n",
    "                         train_annotations: pd.DataFrame, \n",
    "                         background_dir: str, \n",
    "                         background_percentage: float = 0,\n",
    "                         random_state: int = 42) -> List[str]:\n",
    "    \"\"\"\n",
    "    Get random background images that don't contain any annotations\n",
    "    Args:\n",
    "        train_image_count: Number of training images (not boxes)\n",
    "        train_annotations: Full annotations DataFrame\n",
    "        background_dir: Directory containing background images\n",
    "        background_percentage: Percentage of training images to use as background\n",
    "        random_state: Random seed\n",
    "    Returns:\n",
    "        List of selected background image IDs\n",
    "    \"\"\"\n",
    "    # Calculate number of background images needed\n",
    "    num_background = int(train_image_count * (background_percentage / 100))\n",
    "    \n",
    "    # Get all image IDs that contain any annotations\n",
    "    annotated_images = set(train_annotations['ImageID'].unique())\n",
    "    \n",
    "    # Get all available background images\n",
    "    try:\n",
    "        background_files = [f[:-4] for f in os.listdir(background_dir) if f.endswith('.jpg')]\n",
    "    except FileNotFoundError:\n",
    "        logging.warning(f\"Background directory not found: {background_dir}\")\n",
    "        return []\n",
    "    \n",
    "    # Filter out images that have annotations\n",
    "    valid_backgrounds = list(set(background_files) - annotated_images)\n",
    "    \n",
    "    if len(valid_backgrounds) < num_background:\n",
    "        logging.warning(\n",
    "            f\"Only {len(valid_backgrounds)} valid background images available, \"\n",
    "            f\"requested {num_background}\"\n",
    "        )\n",
    "        num_background = len(valid_backgrounds)\n",
    "    \n",
    "    # Randomly select background images\n",
    "    random.seed(random_state)\n",
    "    selected_backgrounds = random.sample(valid_backgrounds, num_background)\n",
    "    \n",
    "    logging.info(f\"Selected {len(selected_backgrounds)} background images\")\n",
    "    return selected_backgrounds\n",
    "\n",
    "def process_background_images(background_images: List[str], \n",
    "                            background_dir: str, \n",
    "                            output_dir: str):\n",
    "    \"\"\"\n",
    "    Process background images and add them to the dataset\n",
    "    Args:\n",
    "        background_images: List of background image IDs\n",
    "        background_dir: Source directory for background images\n",
    "        output_dir: Output directory for dataset\n",
    "    \"\"\"\n",
    "    for image_id in tqdm(background_images, desc=\"Processing background images\"):\n",
    "        # Create empty label file\n",
    "        label_path = os.path.join(output_dir, 'labels', f\"{image_id}.txt\")\n",
    "        open(label_path, 'w').close()  # Create empty file\n",
    "        \n",
    "        # Create symbolic link to background image\n",
    "        src_img_path = os.path.join(background_dir, f\"{image_id}.jpg\")\n",
    "        dst_img_path = os.path.join(output_dir, 'images', f\"{image_id}.jpg\")\n",
    "        \n",
    "        if os.path.exists(src_img_path):\n",
    "            if not os.path.exists(dst_img_path):\n",
    "                try:\n",
    "                    os.symlink(src_img_path, dst_img_path)\n",
    "                except OSError as e:\n",
    "                    logging.error(f\"Failed to create symlink for {image_id}: {str(e)}\")\n",
    "        else:\n",
    "            logging.warning(f\"Background image not found: {src_img_path}\")\n",
    "\n",
    "def save_results(results: List[Dict], project_dir: str):\n",
    "    \"\"\"\n",
    "    Save training results to CSV file\n",
    "    Args:\n",
    "        results: List of dictionaries containing training metrics\n",
    "        project_dir: Directory to save results\n",
    "    \"\"\"\n",
    "    results_path = os.path.join(project_dir, 'training_metrics.csv')\n",
    "    \n",
    "    # Collect all possible column names from all results\n",
    "    csv_columns = set()\n",
    "    for result in results:\n",
    "        csv_columns.update(result.keys())\n",
    "    \n",
    "    csv_columns = sorted(list(csv_columns))  # Sort columns for consistency\n",
    "    \n",
    "    try:\n",
    "        with open(results_path, 'w', newline='') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=csv_columns)\n",
    "            writer.writeheader()\n",
    "            for result in results:\n",
    "                # Fill in missing values with None\n",
    "                row = {col: result.get(col, None) for col in csv_columns}\n",
    "                writer.writerow(row)\n",
    "        \n",
    "        logging.info(f\"Results saved to {results_path}\")\n",
    "        \n",
    "    except IOError as e:\n",
    "        logging.error(f\"Failed to save results to CSV: {str(e)}\")\n",
    "\n",
    "def verify_dataset_integrity(dataset_dir: str, \n",
    "                           class_mapping: Dict[str, int]) -> bool:\n",
    "    \"\"\"\n",
    "    Verify the integrity of the created dataset\n",
    "    \"\"\"\n",
    "    images_dir = os.path.join(dataset_dir, 'images')\n",
    "    labels_dir = os.path.join(dataset_dir, 'labels')\n",
    "    \n",
    "    # Check directory structure\n",
    "    if not all(os.path.exists(d) for d in [images_dir, labels_dir]):\n",
    "        logging.error(\"Dataset directory structure is invalid\")\n",
    "        return False\n",
    "    \n",
    "    # Get image and label files\n",
    "    image_files = set(f[:-4] for f in os.listdir(images_dir) if f.endswith('.jpg'))\n",
    "    label_files = set(f[:-4] for f in os.listdir(labels_dir) if f.endswith('.txt'))\n",
    "    \n",
    "    # Check for missing pairs\n",
    "    missing_labels = image_files - label_files\n",
    "    missing_images = label_files - image_files\n",
    "    \n",
    "    if missing_labels:\n",
    "        logging.error(f\"Found {len(missing_labels)} images without labels\")\n",
    "        return False\n",
    "    \n",
    "    if missing_images:\n",
    "        logging.error(f\"Found {len(missing_images)} labels without images\")\n",
    "        # Clean up orphaned label files\n",
    "        for image_id in missing_images:\n",
    "            os.remove(os.path.join(labels_dir, f\"{image_id}.txt\"))\n",
    "        logging.info(\"Removed orphaned label files\")\n",
    "        \n",
    "    # Verify label format and class indices\n",
    "    valid_classes = set(class_mapping.values())\n",
    "    boxes_per_class = {idx: 0 for idx in valid_classes}\n",
    "    \n",
    "    for label_file in os.listdir(labels_dir):\n",
    "        if not label_file.endswith('.txt'):\n",
    "            continue\n",
    "            \n",
    "        with open(os.path.join(labels_dir, label_file), 'r') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    values = line.strip().split()\n",
    "                    if len(values) != 5:\n",
    "                        logging.error(f\"Invalid label format in {label_file} line {line_num}\")\n",
    "                        return False\n",
    "                    \n",
    "                    class_idx = int(values[0])\n",
    "                    if class_idx not in valid_classes:\n",
    "                        logging.error(f\"Invalid class index in {label_file} line {line_num}: {class_idx}\")\n",
    "                        return False\n",
    "                    \n",
    "                    boxes_per_class[class_idx] += 1\n",
    "                        \n",
    "                    # Verify bounding box coordinates are in range [0, 1]\n",
    "                    coords = [float(v) for v in values[1:]]\n",
    "                    if not all(0 <= v <= 1 for v in coords):\n",
    "                        logging.error(f\"Invalid coordinates in {label_file} line {line_num}\")\n",
    "                        return False\n",
    "                        \n",
    "                except ValueError as e:\n",
    "                    logging.error(f\"Invalid value in {label_file} line {line_num}: {str(e)}\")\n",
    "                    return False\n",
    "    \n",
    "    # Log box distribution\n",
    "    logging.info(\"\\nBounding box distribution:\")\n",
    "    for class_idx, count in boxes_per_class.items():\n",
    "        logging.info(f\"Class {class_idx}: {count} boxes\")\n",
    "    \n",
    "    logging.info(\"Dataset integrity verification passed\")\n",
    "    return True\n",
    "\n",
    "# CELL 2: Data Loading and Preprocessing\n",
    "class MultiClassDataLoader:\n",
    "    def __init__(self, class_desc_path: str, annotations_path: str, image_dir: str):\n",
    "        self.class_descriptions = pd.read_csv(class_desc_path)\n",
    "        self.train_annotations = pd.read_csv(annotations_path)\n",
    "        self.image_dir = image_dir\n",
    "        self.class_mapping = {}  # LabelName to index mapping\n",
    "        self.reverse_mapping = {}  # index to DisplayName mapping\n",
    "        \n",
    "        # Get available image IDs from directory\n",
    "        self.available_image_ids = set(\n",
    "            f[:-4] for f in os.listdir(image_dir) \n",
    "            if f.endswith('.jpg')\n",
    "        )\n",
    "        logging.info(f\"Found {len(self.available_image_ids)} images in directory\")\n",
    "        \n",
    "        # Filter annotations to only include available images\n",
    "        self.train_annotations = self.train_annotations[\n",
    "            self.train_annotations['ImageID'].isin(self.available_image_ids)\n",
    "        ]\n",
    "        logging.info(f\"Filtered annotations to {len(self.train_annotations)} rows with available images\")\n",
    "        \n",
    "    def get_training_classes(self) -> List[str]:\n",
    "        \"\"\"Get list of classes marked for use in model\"\"\"\n",
    "        # Get classes marked for training\n",
    "        training_classes = self.class_descriptions[\n",
    "            self.class_descriptions['UseInModel'] == True\n",
    "        ]['DisplayName'].tolist()\n",
    "        \n",
    "        # Filter to only include classes that have sufficient data\n",
    "        valid_classes = []\n",
    "        for class_name in training_classes:\n",
    "            label_name = self.class_descriptions[\n",
    "                self.class_descriptions['DisplayName'] == class_name\n",
    "            ]['LabelName'].iloc[0]\n",
    "            \n",
    "            # Count annotations for this class\n",
    "            class_count = len(self.train_annotations[\n",
    "                self.train_annotations['LabelName'] == label_name\n",
    "            ])\n",
    "            \n",
    "            if class_count > 0:\n",
    "                valid_classes.append(class_name)\n",
    "                logging.info(f\"Class {class_name}: {class_count} annotations in available images\")\n",
    "            else:\n",
    "                logging.warning(f\"Class {class_name}: no annotations in available images, skipping\")\n",
    "        \n",
    "        logging.info(f\"Found {len(valid_classes)} classes with data in available images\")\n",
    "        return valid_classes\n",
    "    \n",
    "    def create_class_mappings(self, training_classes: List[str]):\n",
    "        \"\"\"Create mappings between class names and indices\"\"\"\n",
    "        self.class_mapping.clear()\n",
    "        self.reverse_mapping.clear()\n",
    "        \n",
    "        for idx, class_name in enumerate(training_classes):\n",
    "            label_name = self.class_descriptions[\n",
    "                self.class_descriptions['DisplayName'] == class_name\n",
    "            ]['LabelName'].iloc[0]\n",
    "            self.class_mapping[label_name] = idx\n",
    "            self.reverse_mapping[idx] = class_name\n",
    "            \n",
    "def filter_annotations(class_loader: MultiClassDataLoader,\n",
    "                      box_count_per_class: int,\n",
    "                      fixed_val_size: int) -> Tuple[Dict[str, pd.DataFrame], Dict[str, pd.DataFrame]]:\n",
    "    \"\"\"\n",
    "    Filter annotations ensuring proper box counts per class and handling multiple boxes per image\n",
    "    Returns:\n",
    "        Tuple of (train_data, val_data) dictionaries\n",
    "    \"\"\"\n",
    "    train_data = {}\n",
    "    val_data = {}\n",
    "    \n",
    "    for label_name, class_idx in class_loader.class_mapping.items():\n",
    "        # Get all annotations for this class (already filtered for available images)\n",
    "        class_annotations = class_loader.train_annotations[\n",
    "            class_loader.train_annotations['LabelName'] == label_name\n",
    "        ]\n",
    "        \n",
    "        total_boxes_needed = box_count_per_class + fixed_val_size\n",
    "        if len(class_annotations) < total_boxes_needed:\n",
    "            logging.warning(\n",
    "                f\"Insufficient boxes for class {class_loader.reverse_mapping[class_idx]}. \"\n",
    "                f\"Required: {total_boxes_needed}, Available: {len(class_annotations)}\"\n",
    "            )\n",
    "            continue\n",
    "        \n",
    "        # Shuffle all annotations for this class\n",
    "        shuffled_annotations = class_annotations.sample(frac=1, random_state=42)\n",
    "        \n",
    "        # Take required number of boxes for validation\n",
    "        val_data[label_name] = shuffled_annotations[:fixed_val_size]\n",
    "        \n",
    "        # Take required number of boxes for training\n",
    "        train_data[label_name] = shuffled_annotations[fixed_val_size:fixed_val_size + box_count_per_class]\n",
    "        \n",
    "        # Log statistics\n",
    "        train_images = len(train_data[label_name]['ImageID'].unique())\n",
    "        val_images = len(val_data[label_name]['ImageID'].unique())\n",
    "        logging.info(f\"Class {class_loader.reverse_mapping[class_idx]}:\")\n",
    "        logging.info(f\"  Training: {len(train_data[label_name])} boxes in {train_images} images\")\n",
    "        logging.info(f\"  Validation: {len(val_data[label_name])} boxes in {val_images} images\")\n",
    "    \n",
    "    return train_data, val_data\n",
    "\n",
    "# CELL 3: Dataset Creation\n",
    "class MultiClassYOLODataset(Dataset):\n",
    "    def __init__(self, annotations_dict: Dict[str, pd.DataFrame], \n",
    "                 image_dir: str, class_mapping: Dict[str, int],\n",
    "                 transforms=None):\n",
    "        self.annotations_dict = annotations_dict\n",
    "        self.image_dir = image_dir\n",
    "        self.class_mapping = class_mapping\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        # Combine all annotations and get unique image IDs\n",
    "        all_annotations = pd.concat(annotations_dict.values())\n",
    "        self.image_ids = all_annotations['ImageID'].unique()\n",
    "        self.image_annotations = all_annotations.groupby('ImageID')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.image_ids[idx]\n",
    "        img_path = os.path.join(self.image_dir, f\"{image_id}.jpg\")\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        \n",
    "        # Get all annotations for this image\n",
    "        image_annotations = self.image_annotations.get_group(image_id)\n",
    "        \n",
    "        # Convert bounding boxes to YOLO format\n",
    "        labels = []\n",
    "        for _, row in image_annotations.iterrows():\n",
    "            class_idx = self.class_mapping[row['LabelName']]\n",
    "            x_min, x_max = row['XMin'], row['XMax']\n",
    "            y_min, y_max = row['YMin'], row['YMax']\n",
    "            \n",
    "            x_center = (x_min + x_max) / 2\n",
    "            y_center = (y_min + y_max) / 2\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            \n",
    "            labels.append([class_idx, x_center, y_center, width, height])\n",
    "            \n",
    "        return img_path, torch.tensor(labels)\n",
    "\n",
    "def create_multi_class_dataset(annotations_dict: Dict[str, pd.DataFrame],\n",
    "                             image_dir: str,\n",
    "                             output_dir: str,\n",
    "                             class_mapping: Dict[str, int]):\n",
    "    \"\"\"\n",
    "    Create YOLO dataset structure for multiple classes, handling multiple bounding boxes per image\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "    \n",
    "    # Combine all annotations\n",
    "    all_annotations = pd.concat(annotations_dict.values())\n",
    "    \n",
    "    # Get unique image IDs\n",
    "    unique_image_ids = all_annotations['ImageID'].unique()\n",
    "    logging.info(f\"Processing {len(unique_image_ids)} unique images\")\n",
    "    \n",
    "    # Process each unique image\n",
    "    for image_id in tqdm(unique_image_ids, desc=\"Creating dataset\"):\n",
    "        # Get all annotations for this image\n",
    "        image_annots = all_annotations[all_annotations['ImageID'] == image_id]\n",
    "        \n",
    "        # Create label file with all bounding boxes\n",
    "        label_path = os.path.join(output_dir, 'labels', f\"{image_id}.txt\")\n",
    "        \n",
    "        with open(label_path, 'w') as f:\n",
    "            for _, row in image_annots.iterrows():\n",
    "                class_idx = class_mapping[row['LabelName']]\n",
    "                x_center = (row['XMin'] + row['XMax']) / 2\n",
    "                y_center = (row['YMin'] + row['YMax']) / 2\n",
    "                width = row['XMax'] - row['XMin']\n",
    "                height = row['YMax'] - row['YMin']\n",
    "                \n",
    "                f.write(f\"{class_idx} {x_center} {y_center} {width} {height}\\n\")\n",
    "        \n",
    "        # Create symbolic link to image\n",
    "        src_img_path = os.path.join(image_dir, f\"{image_id}.jpg\")\n",
    "        dst_img_path = os.path.join(output_dir, 'images', f\"{image_id}.jpg\")\n",
    "        if os.path.exists(src_img_path):\n",
    "            if not os.path.exists(dst_img_path):\n",
    "                try:\n",
    "                    os.symlink(src_img_path, dst_img_path)\n",
    "                except OSError as e:\n",
    "                    logging.error(f\"Failed to create symlink for {image_id}: {str(e)}\")\n",
    "                    # If symlink fails, try copying the file\n",
    "                    try:\n",
    "                        shutil.copy2(src_img_path, dst_img_path)\n",
    "                    except IOError as e:\n",
    "                        logging.error(f\"Failed to copy image {image_id}: {str(e)}\")\n",
    "        else:\n",
    "            logging.warning(f\"Image not found: {src_img_path}\")\n",
    "            # Remove the label file if image doesn't exist\n",
    "            os.remove(label_path)\n",
    "\n",
    "\n",
    "# CELL 4: Training Functions\n",
    "def train_model(model, yaml_path, run_dir, box_count_per_class, max_epochs):\n",
    "    \"\"\"\n",
    "    Train the YOLO model with all hyperparameters\n",
    "    Args:\n",
    "        model: Initialized YOLO model\n",
    "        yaml_path: Path to dataset configuration\n",
    "        run_dir: Directory for saving results\n",
    "        box_count_per_class: Number of boxes per class used in training\n",
    "        max_epochs: Maximum number of training epochs\n",
    "    Returns:\n",
    "        Training results\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = model.train(\n",
    "            data=yaml_path,\n",
    "            epochs=max_epochs,\n",
    "            imgsz=640,\n",
    "            # Model hyperparameters\n",
    "            batch=16,              # Batch size\n",
    "            workers=6,             # Number of worker threads\n",
    "            device=0,              # GPU device number\n",
    "            # conf=0.1,           # Confidence threshold\n",
    "            # iou=0.1,            # IoU threshold\n",
    "            \n",
    "            # Training parameters\n",
    "            project=run_dir,\n",
    "            name=f'yolo_boxes_{box_count_per_class}',\n",
    "            patience=30,           # Early stopping patience\n",
    "            save=True,            # Save checkpoints\n",
    "            save_period=10,       # Save every N epochs\n",
    "            \n",
    "            # Learning rate parameters\n",
    "            # lr0=0.00001,        # Initial learning rate\n",
    "            # lrf=0.000001,       # Final learning rate\n",
    "            # warmup_epochs=3,    # Number of warmup epochs\n",
    "            # warmup_momentum=0.8,# Warmup momentum\n",
    "            # warmup_bias_lr=0.1, # Warmup bias learning rate\n",
    "            \n",
    "            # Loss weights\n",
    "            # box=7.5,            # Box loss weight\n",
    "            # cls=0.5,            # Class loss weight\n",
    "            # dfl=1.5,            # DFL loss weight\n",
    "            \n",
    "            # Visualization and logging\n",
    "            plots=True,           # Generate plots\n",
    "            verbose=True,         # Verbose output\n",
    "            \n",
    "            # Regularization\n",
    "            # weight_decay=0.0005,# Weight decay\n",
    "            # dropout=0.2,        # Dropout rate\n",
    "            \n",
    "            # Data augmentation (disabled in original)\n",
    "            # hsv_h=0,           # HSV-Hue augmentation\n",
    "            # hsv_s=0,           # HSV-Saturation augmentation\n",
    "            # hsv_v=0,           # HSV-Value augmentation\n",
    "            # translate=0,        # Translation augmentation\n",
    "            # scale=0,           # Scaling augmentation\n",
    "            # fliplr=0,          # Horizontal flip augmentation\n",
    "            # mosaic=0,          # Mosaic augmentation\n",
    "            # erasing=0,         # Random erasing\n",
    "            # crop_fraction=1     # Crop fraction\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed with error: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def save_training_results(results, run_dir, model_dir, box_count_per_class):\n",
    "    \"\"\"Save model checkpoints and training metrics\"\"\"\n",
    "    try:\n",
    "        # Save models\n",
    "        yolo_output_dir = os.path.join(run_dir, f'yolo_boxes_{box_count_per_class}')\n",
    "        \n",
    "        # Save best model\n",
    "        if os.path.exists(os.path.join(yolo_output_dir, 'weights', 'best.pt')):\n",
    "            best_model_path = os.path.join(model_dir, f'model_best_boxes_{box_count_per_class}.pt')\n",
    "            shutil.copy2(\n",
    "                os.path.join(yolo_output_dir, 'weights', 'best.pt'),\n",
    "                best_model_path\n",
    "            )\n",
    "        \n",
    "        # Save final model\n",
    "        if os.path.exists(os.path.join(yolo_output_dir, 'weights', 'last.pt')):\n",
    "            final_model_path = os.path.join(model_dir, f'model_final_boxes_{box_count_per_class}.pt')\n",
    "            shutil.copy2(\n",
    "                os.path.join(yolo_output_dir, 'weights', 'last.pt'),\n",
    "                final_model_path\n",
    "            )\n",
    "        \n",
    "        # Collect metrics\n",
    "        metrics = {\n",
    "            'BoundingBoxCountPerClass': box_count_per_class,\n",
    "            'ModelDirectory': model_dir,\n",
    "            'FinalEpoch': results.epoch\n",
    "        }\n",
    "        \n",
    "        # Add per-class metrics if available\n",
    "        if hasattr(results, 'results_dict'):\n",
    "            metrics_dict = results.results_dict\n",
    "            \n",
    "            # Overall metrics\n",
    "            metrics.update({\n",
    "                'Precision': float(metrics_dict.get('metrics/precision', 0.0)),\n",
    "                'Recall': float(metrics_dict.get('metrics/recall', 0.0)),\n",
    "                'mAP50': float(metrics_dict.get('metrics/mAP50', 0.0)),\n",
    "                'mAP50-95': float(metrics_dict.get('metrics/mAP50-95', 0.0))\n",
    "            })\n",
    "            \n",
    "            # Add per-class metrics if available\n",
    "            for class_idx in range(results.num_classes):\n",
    "                class_prefix = f'metrics/precision_{class_idx}'\n",
    "                if class_prefix in metrics_dict:\n",
    "                    metrics.update({\n",
    "                        f'Precision_Class_{class_idx}': float(metrics_dict[f'metrics/precision_{class_idx}']),\n",
    "                        f'Recall_Class_{class_idx}': float(metrics_dict[f'metrics/recall_{class_idx}']),\n",
    "                        f'mAP50_Class_{class_idx}': float(metrics_dict[f'metrics/mAP50_{class_idx}']),\n",
    "                        f'mAP50-95_Class_{class_idx}': float(metrics_dict[f'metrics/mAP50-95_{class_idx}'])\n",
    "                    })\n",
    "        \n",
    "        return metrics\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save training results: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def train_multi_class_yolo(box_count_per_class: int,\n",
    "                          image_dir: str,\n",
    "                          project_dir: str,\n",
    "                          class_loader: MultiClassDataLoader,\n",
    "                          fixed_val_size: int = 500,\n",
    "                          max_epochs: int = 500,\n",
    "                          background_percentage: float = 0):  # Set default to 0\n",
    "    \"\"\"Train YOLO model for multiple classes\"\"\"\n",
    "    \n",
    "    # Create run directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    run_dir = os.path.join(project_dir, f'multi_class_run_{box_count_per_class}_boxes_{timestamp}')\n",
    "    dataset_dir = os.path.join(run_dir, 'dataset')\n",
    "    model_dir = os.path.join(run_dir, 'models')\n",
    "    \n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "    os.makedirs(dataset_dir, exist_ok=True)\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "    \n",
    "    # Get training classes and create mappings\n",
    "    training_classes = class_loader.get_training_classes()\n",
    "    class_loader.create_class_mappings(training_classes)\n",
    "    \n",
    "    # Filter annotations for each class - now returns tuple (train_data, val_data)\n",
    "    train_data, val_data = filter_annotations(class_loader, box_count_per_class, fixed_val_size)\n",
    "    \n",
    "    if not train_data or not val_data:\n",
    "        logging.error(\"No classes had sufficient data for training\")\n",
    "        return None\n",
    "    \n",
    "    # Create dataset structure\n",
    "    train_dir = os.path.join(dataset_dir, 'train')\n",
    "    val_dir = os.path.join(dataset_dir, 'val')\n",
    "    \n",
    "    # Create training dataset\n",
    "    create_multi_class_dataset(\n",
    "        train_data, \n",
    "        image_dir, \n",
    "        train_dir,\n",
    "        class_loader.class_mapping\n",
    "    )\n",
    "    \n",
    "    # Verify training dataset integrity\n",
    "    logging.info(\"Verifying training dataset integrity...\")\n",
    "    if not verify_dataset_integrity(train_dir, class_loader.class_mapping):\n",
    "        logging.error(\"Training dataset verification failed. Aborting training.\")\n",
    "        return None\n",
    "    \n",
    "    # Create validation dataset\n",
    "    create_multi_class_dataset(\n",
    "        val_data, \n",
    "        image_dir, \n",
    "        val_dir,\n",
    "        class_loader.class_mapping\n",
    "    )\n",
    "    \n",
    "    # Verify validation dataset integrity\n",
    "    logging.info(\"Verifying validation dataset integrity...\")\n",
    "    if not verify_dataset_integrity(val_dir, class_loader.class_mapping):\n",
    "        logging.error(\"Validation dataset verification failed. Aborting training.\")\n",
    "        return None\n",
    "    \n",
    "    # Create YAML configuration\n",
    "    yaml_path = os.path.join(run_dir, 'dataset.yaml')\n",
    "    create_yaml_file(\n",
    "        train_dir, val_dir, yaml_path,\n",
    "        num_classes=len(training_classes),\n",
    "        class_names=[class_loader.reverse_mapping[i] for i in range(len(training_classes))]\n",
    "    )\n",
    "    \n",
    "    # Print dataset summary\n",
    "    logging.info(\"\\nDataset Summary:\")\n",
    "    logging.info(f\"Number of classes: {len(training_classes)}\")\n",
    "    \n",
    "    # Calculate total images and boxes\n",
    "    train_images = len(os.listdir(os.path.join(train_dir, 'images')))\n",
    "    val_images = len(os.listdir(os.path.join(val_dir, 'images')))\n",
    "    \n",
    "    logging.info(f\"Training images: {train_images}\")\n",
    "    logging.info(f\"Validation images: {val_images}\")\n",
    "    \n",
    "    # Class distribution summary\n",
    "    logging.info(\"\\nClass Distribution:\")\n",
    "    for class_idx, class_name in class_loader.reverse_mapping.items():\n",
    "        # Count boxes in training set\n",
    "        train_count = sum(1 for f in os.listdir(os.path.join(train_dir, 'labels'))\n",
    "                         for line in open(os.path.join(train_dir, 'labels', f))\n",
    "                         if line.startswith(f\"{class_idx} \"))\n",
    "        \n",
    "        # Count boxes in validation set\n",
    "        val_count = sum(1 for f in os.listdir(os.path.join(val_dir, 'labels'))\n",
    "                       for line in open(os.path.join(val_dir, 'labels', f))\n",
    "                       if line.startswith(f\"{class_idx} \"))\n",
    "        \n",
    "        logging.info(f\"Class {class_name}: {train_count} training boxes, {val_count} validation boxes\")\n",
    "    \n",
    "    # Initialize and train model\n",
    "    try:\n",
    "        model = YOLO('yolov8s.pt')\n",
    "        results = train_model(model, yaml_path, run_dir, box_count_per_class, max_epochs)\n",
    "        save_training_results(results, run_dir, model_dir, box_count_per_class)\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during training: {str(e)}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 22:26:09,293 - INFO - Found 51044 images in directory\n",
      "2024-11-19 22:26:10,266 - INFO - Filtered annotations to 530284 rows with available images\n",
      "2024-11-19 22:26:10,313 - INFO - Class Footwear: 59779 annotations in available images\n",
      "2024-11-19 22:26:10,347 - INFO - Class Car: 17787 annotations in available images\n",
      "2024-11-19 22:26:10,385 - INFO - Class Jeans: 16440 annotations in available images\n",
      "2024-11-19 22:26:10,420 - INFO - Class Glasses: 10228 annotations in available images\n",
      "2024-11-19 22:26:10,452 - INFO - Class Dress: 10704 annotations in available images\n",
      "2024-11-19 22:26:10,484 - INFO - Class Hat: 9434 annotations in available images\n",
      "2024-11-19 22:26:10,517 - INFO - Class Laptop: 9327 annotations in available images\n",
      "2024-11-19 22:26:10,551 - INFO - Class Shirt: 7465 annotations in available images\n",
      "2024-11-19 22:26:10,583 - INFO - Class Mobile phone: 6365 annotations in available images\n",
      "2024-11-19 22:26:10,615 - INFO - Class Television: 3789 annotations in available images\n",
      "2024-11-19 22:26:10,616 - INFO - Found 10 classes with data in available images\n",
      "2024-11-19 22:26:10,673 - INFO - Class Footwear:\n",
      "2024-11-19 22:26:10,674 - INFO -   Training: 3000 boxes in 2391 images\n",
      "2024-11-19 22:26:10,675 - INFO -   Validation: 500 boxes in 478 images\n",
      "2024-11-19 22:26:10,713 - INFO - Class Car:\n",
      "2024-11-19 22:26:10,714 - INFO -   Training: 3000 boxes in 2256 images\n",
      "2024-11-19 22:26:10,715 - INFO -   Validation: 500 boxes in 476 images\n",
      "2024-11-19 22:26:10,752 - INFO - Class Jeans:\n",
      "2024-11-19 22:26:10,754 - INFO -   Training: 3000 boxes in 2253 images\n",
      "2024-11-19 22:26:10,755 - INFO -   Validation: 500 boxes in 468 images\n",
      "2024-11-19 22:26:10,791 - INFO - Class Glasses:\n",
      "2024-11-19 22:26:10,794 - INFO -   Training: 3000 boxes in 2653 images\n",
      "2024-11-19 22:26:10,794 - INFO -   Validation: 500 boxes in 489 images\n",
      "2024-11-19 22:26:10,827 - INFO - Class Dress:\n",
      "2024-11-19 22:26:10,829 - INFO -   Training: 3000 boxes in 2437 images\n",
      "2024-11-19 22:26:10,829 - INFO -   Validation: 500 boxes in 479 images\n",
      "2024-11-19 22:26:10,860 - INFO - Class Hat:\n",
      "2024-11-19 22:26:10,861 - INFO -   Training: 3000 boxes in 2371 images\n",
      "2024-11-19 22:26:10,862 - INFO -   Validation: 500 boxes in 472 images\n",
      "2024-11-19 22:26:10,895 - INFO - Class Laptop:\n",
      "2024-11-19 22:26:10,896 - INFO -   Training: 3000 boxes in 2275 images\n",
      "2024-11-19 22:26:10,897 - INFO -   Validation: 500 boxes in 466 images\n",
      "2024-11-19 22:26:10,928 - INFO - Class Shirt:\n",
      "2024-11-19 22:26:10,929 - INFO -   Training: 3000 boxes in 2522 images\n",
      "2024-11-19 22:26:10,929 - INFO -   Validation: 500 boxes in 487 images\n",
      "2024-11-19 22:26:10,961 - INFO - Class Mobile phone:\n",
      "2024-11-19 22:26:10,962 - INFO -   Training: 3000 boxes in 2309 images\n",
      "2024-11-19 22:26:10,963 - INFO -   Validation: 500 boxes in 468 images\n",
      "2024-11-19 22:26:10,994 - INFO - Class Television:\n",
      "2024-11-19 22:26:10,994 - INFO -   Training: 3000 boxes in 2285 images\n",
      "2024-11-19 22:26:10,995 - INFO -   Validation: 500 boxes in 459 images\n",
      "2024-11-19 22:26:11,008 - INFO - Processing 22454 unique images\n",
      "Creating dataset: 100%|██████████| 22454/22454 [01:50<00:00, 203.00it/s]\n",
      "2024-11-19 22:28:01,628 - INFO - Verifying training dataset integrity...\n",
      "2024-11-19 22:28:04,430 - INFO - \n",
      "Bounding box distribution:\n",
      "2024-11-19 22:28:04,431 - INFO - Class 0: 3000 boxes\n",
      "2024-11-19 22:28:04,432 - INFO - Class 1: 3000 boxes\n",
      "2024-11-19 22:28:04,433 - INFO - Class 2: 3000 boxes\n",
      "2024-11-19 22:28:04,434 - INFO - Class 3: 3000 boxes\n",
      "2024-11-19 22:28:04,435 - INFO - Class 4: 3000 boxes\n",
      "2024-11-19 22:28:04,436 - INFO - Class 5: 3000 boxes\n",
      "2024-11-19 22:28:04,437 - INFO - Class 6: 3000 boxes\n",
      "2024-11-19 22:28:04,437 - INFO - Class 7: 3000 boxes\n",
      "2024-11-19 22:28:04,438 - INFO - Class 8: 3000 boxes\n",
      "2024-11-19 22:28:04,438 - INFO - Class 9: 3000 boxes\n",
      "2024-11-19 22:28:04,439 - INFO - Dataset integrity verification passed\n",
      "2024-11-19 22:28:04,446 - INFO - Processing 4692 unique images\n",
      "Creating dataset: 100%|██████████| 4692/4692 [00:07<00:00, 641.94it/s]\n",
      "2024-11-19 22:28:11,759 - INFO - Verifying validation dataset integrity...\n",
      "2024-11-19 22:28:12,321 - INFO - \n",
      "Bounding box distribution:\n",
      "2024-11-19 22:28:12,322 - INFO - Class 0: 500 boxes\n",
      "2024-11-19 22:28:12,322 - INFO - Class 1: 500 boxes\n",
      "2024-11-19 22:28:12,323 - INFO - Class 2: 500 boxes\n",
      "2024-11-19 22:28:12,323 - INFO - Class 3: 500 boxes\n",
      "2024-11-19 22:28:12,324 - INFO - Class 4: 500 boxes\n",
      "2024-11-19 22:28:12,324 - INFO - Class 5: 500 boxes\n",
      "2024-11-19 22:28:12,325 - INFO - Class 6: 500 boxes\n",
      "2024-11-19 22:28:12,325 - INFO - Class 7: 500 boxes\n",
      "2024-11-19 22:28:12,326 - INFO - Class 8: 500 boxes\n",
      "2024-11-19 22:28:12,327 - INFO - Class 9: 500 boxes\n",
      "2024-11-19 22:28:12,327 - INFO - Dataset integrity verification passed\n",
      "2024-11-19 22:28:12,330 - INFO - Created YAML configuration file at E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset.yaml\n",
      "2024-11-19 22:28:12,331 - INFO - \n",
      "Dataset Summary:\n",
      "2024-11-19 22:28:12,331 - INFO - Number of classes: 10\n",
      "2024-11-19 22:28:12,346 - INFO - Training images: 22454\n",
      "2024-11-19 22:28:12,347 - INFO - Validation images: 4692\n",
      "2024-11-19 22:28:12,348 - INFO - \n",
      "Class Distribution:\n",
      "2024-11-19 22:28:15,667 - INFO - Class Footwear: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:18,891 - INFO - Class Car: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:22,100 - INFO - Class Jeans: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:25,297 - INFO - Class Glasses: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:28,546 - INFO - Class Dress: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:31,736 - INFO - Class Hat: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:34,943 - INFO - Class Laptop: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:38,238 - INFO - Class Shirt: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:41,465 - INFO - Class Mobile phone: 3000 training boxes, 500 validation boxes\n",
      "2024-11-19 22:28:44,693 - INFO - Class Television: 3000 training boxes, 500 validation boxes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.34 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.23  Python-3.10.0 torch-2.5.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset.yaml, epochs=500, time=None, patience=30, batch=16, imgsz=640, save=True, save_period=10, cache=False, device=0, workers=6, project=E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610, name=yolo_boxes_3000, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\n",
      "Overriding model.yaml nc=80 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119918  ultralytics.nn.modules.head.Detect           [10, [128, 256, 512]]         \n",
      "Model summary: 225 layers, 11,139,470 parameters, 11,139,454 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset\\train\\labels... 22454 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22454/22454 [00:14<00:00, 1578.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset\\train\\images\\4512a4e6351696f6.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset\\train\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset\\val\\labels... 4692 images, 0 backgrounds, 0 corrupt: 100%|██████████| 4692/4692 [00:03<00:00, 1410.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\dataset\\val\\labels.cache\n",
      "Plotting labels to E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 6 dataloader workers\n",
      "Logging results to \u001b[1mE:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\u001b[0m\n",
      "Starting training for 500 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/500      4.12G      1.137      2.234      1.317         15        640: 100%|██████████| 1404/1404 [04:12<00:00,  5.56it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [42:20<00:00, 17.28s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.418      0.449      0.323      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/500      4.05G      1.158      1.694      1.287         16        640: 100%|██████████| 1404/1404 [03:59<00:00,  5.87it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.279       0.45       0.29       0.19\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/500      4.05G      1.319       1.94        1.4         16        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000       0.35      0.354      0.219      0.134\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/500      3.76G      1.408      2.108      1.472         21        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.379      0.408      0.255      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/500      3.78G      1.348      1.967      1.436         17        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.309      0.436      0.293      0.191\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/500      3.76G      1.314      1.892      1.412         12        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.451        0.4      0.306      0.206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/500      3.77G      1.274      1.812      1.387         18        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.418      0.446      0.326      0.219\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/500      3.76G      1.249      1.756      1.361          9        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.411      0.473       0.34      0.232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/500      3.76G      1.231      1.705      1.353         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.412      0.481      0.331      0.225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/500      3.75G      1.216      1.671      1.342         14        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.446      0.459      0.362      0.247\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/500      3.75G      1.203      1.647      1.327         10        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.428      0.494      0.359       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/500      3.75G      1.197      1.638      1.321         12        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.441       0.49      0.368      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/500      3.76G      1.177      1.609      1.312          9        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.447      0.476      0.376      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/500      3.75G      1.165      1.574        1.3         11        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.434      0.503      0.384      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/500      3.76G      1.158       1.56      1.293         15        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.443      0.486      0.381      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/500      3.74G      1.158      1.545      1.292         11        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.425      0.509      0.384      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/500      3.76G      1.147      1.531      1.288         16        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000       0.44      0.503      0.389      0.277\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/500      3.75G      1.137      1.517      1.283         11        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.432        0.5      0.393       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/500      3.76G      1.134      1.506      1.279         18        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.433      0.517      0.391      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/500      3.75G      1.134      1.501      1.277         13        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.436      0.514      0.398      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/500      3.75G      1.127      1.495      1.272         20        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.454      0.497      0.402      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/500      3.75G      1.117      1.467      1.262         15        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.455      0.501      0.407      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/500      3.75G      1.112      1.458      1.257         17        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.446      0.513      0.409      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/500      3.76G      1.114      1.458      1.256         11        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.439      0.517      0.409      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/500      3.74G      1.112      1.456      1.258         18        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.451       0.51      0.411      0.296\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/500      3.74G      1.108      1.441       1.26         15        640: 100%|██████████| 1404/1404 [03:52<00:00,  6.03it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.455      0.508      0.418      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/500      3.75G      1.101      1.431      1.251         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.453      0.517      0.416      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/500      3.75G      1.089      1.425      1.249         11        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.446      0.513      0.414        0.3\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/500      3.75G      1.092      1.413      1.245         10        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.452      0.504      0.414      0.301\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/500      3.75G      1.086      1.403      1.243         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.451      0.517      0.415      0.302\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/500      3.76G      1.084      1.401      1.241         18        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.448      0.521      0.419      0.304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/500      3.76G      1.082      1.395      1.237         11        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.458      0.512      0.423      0.307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/500      3.75G      1.078      1.391      1.233         11        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.452      0.522      0.425      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/500      3.78G      1.075       1.38      1.231         10        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.451      0.528      0.426      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/500      3.75G      1.072      1.378      1.233         20        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.448      0.529      0.424      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/500      3.81G      1.075      1.376      1.232         12        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.348       0.53      0.424      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/500      3.75G      1.068      1.369      1.224         13        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.453       0.52      0.425      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/500      3.76G      1.072      1.367      1.227         13        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.343      0.534      0.426       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/500      3.77G      1.062      1.355      1.224         16        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.344       0.53      0.425       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/500      3.75G       1.06      1.346       1.22         20        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.444      0.533      0.426       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/500      3.75G      1.063      1.351      1.222         16        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.443      0.535      0.426       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/500      3.75G       1.06      1.342      1.219         17        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.439      0.538      0.426       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/500      3.74G      1.061      1.345      1.221         12        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.442      0.537      0.426      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/500      3.76G      1.052      1.333      1.215         14        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.444      0.535      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/500      3.74G      1.053      1.335      1.213         11        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.444      0.532      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/500      3.75G       1.05      1.335      1.212         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.442      0.533      0.426      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/500      3.75G      1.053      1.328      1.211          9        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.442      0.529      0.426      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/500      3.74G       1.05      1.317      1.212         15        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.343      0.531      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/500      3.75G      1.043      1.314      1.207         12        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.346      0.531      0.427      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/500      3.76G      1.043      1.306      1.203         14        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.348       0.53      0.428      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/500      3.75G      1.042      1.304      1.206         13        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.347      0.532      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/500      3.76G      1.036      1.291      1.205         22        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.347       0.53      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/500      3.75G      1.039        1.3      1.203         19        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.346      0.532      0.427      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/500      3.75G      1.034      1.307      1.204          9        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.97it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.345      0.532      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/500      3.75G      1.035      1.295      1.204         17        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.346      0.529      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/500      3.75G      1.035      1.285      1.201         15        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.345      0.531      0.427      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/500      3.75G      1.034       1.28      1.198         23        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.344      0.531      0.426      0.312\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/500      3.73G      1.028      1.283      1.198         20        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.343      0.531      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/500      3.76G      1.028      1.277      1.195         18        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.337       0.54      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/500      3.74G      1.025       1.27      1.192         19        640: 100%|██████████| 1404/1404 [03:54<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.336      0.543      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/500      3.78G      1.028      1.273      1.193         15        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.02it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.334      0.544      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/500      3.75G      1.031      1.277      1.196         12        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.333      0.543      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/500      3.74G      1.021       1.27      1.188         25        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.333      0.542      0.425      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/500      3.75G      1.022      1.263      1.188         15        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.334      0.543      0.424      0.311\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/500      3.75G      1.019      1.259      1.188         18        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.334      0.544      0.424       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/500      3.75G       1.02      1.263      1.188         17        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.332      0.544      0.424       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/500      3.74G       1.02      1.257      1.187          7        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.00it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.329      0.547      0.424       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/500      3.74G      1.021      1.254       1.19          6        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000       0.33      0.545      0.424       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/500      3.78G      1.016      1.256      1.187         20        640: 100%|██████████| 1404/1404 [03:55<00:00,  5.96it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:34<00:00,  4.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000       0.33      0.545      0.423       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/500      3.75G      1.017      1.254      1.188         20        640: 100%|██████████| 1404/1404 [03:57<00:00,  5.92it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.333      0.542      0.423       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/500      3.75G      1.017      1.249      1.187         17        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.332      0.543      0.422       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/500      3.75G      1.025       1.25      1.186         19        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000       0.33      0.549      0.422      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/500      3.75G      1.016      1.241      1.185         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.328       0.55      0.422      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/500      3.75G      1.013      1.236      1.183          9        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.326      0.553      0.422      0.309\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/500      3.75G      1.005      1.227      1.179         16        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.326      0.552      0.421      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/500      3.75G      1.012       1.24      1.178         12        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.98it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.326      0.552      0.421      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/500      3.76G      1.007      1.229      1.177         14        640: 100%|██████████| 1404/1404 [03:53<00:00,  6.01it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.326      0.552      0.421      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/500      3.75G      1.005      1.227      1.179         29        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.325      0.552       0.42      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/500      3.75G      1.006      1.227      1.176         13        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.325      0.552       0.42      0.308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/500      3.75G      1.007      1.231       1.18         16        640: 100%|██████████| 1404/1404 [03:54<00:00,  5.99it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:32<00:00,  4.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.326       0.55       0.42      0.308\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 30 epochs. Best results observed at epoch 50, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=30) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n",
      "\n",
      "80 epochs completed in 6.664 hours.\n",
      "Optimizer stripped from E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating E:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\\weights\\best.pt...\n",
      "Ultralytics 8.3.23  Python-3.10.0 torch-2.5.0+cu118 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
      "Model summary (fused): 168 layers, 11,129,454 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 147/147 [00:33<00:00,  4.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       4692       5000      0.348       0.53      0.428      0.313\n",
      "              Footwear        478        500          0          0     0.0372     0.0167\n",
      "                   Car        476        500       0.35       0.26      0.257      0.183\n",
      "                 Jeans        468        500      0.301      0.148      0.178      0.114\n",
      "               Glasses        489        500      0.506      0.484      0.488      0.254\n",
      "                 Dress        479        500      0.356      0.586        0.4      0.279\n",
      "                   Hat        472        500      0.384      0.666       0.49      0.393\n",
      "                Laptop        466        500      0.399      0.722       0.58      0.422\n",
      "                 Shirt        487        500       0.36      0.708      0.503      0.384\n",
      "          Mobile phone        468        500      0.412      0.864      0.706      0.559\n",
      "            Television        459        500      0.408      0.866      0.636      0.523\n",
      "Speed: 0.4ms preprocess, 1.4ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mE:\\Data 255\\YOLO multi-class\\yolo_training\\multi_class_run_3000_boxes_20241119_222610\\yolo_boxes_3000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 05:10:53,825 - ERROR - Failed to save training results: 'DetMetrics' object has no attribute 'epoch'. See valid attributes below.\n",
      "\n",
      "    Utility class for computing detection metrics such as precision, recall, and mean average precision (mAP) of an\n",
      "    object detection model.\n",
      "\n",
      "    Args:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved. Defaults to current directory.\n",
      "        plot (bool): A flag that indicates whether to plot precision-recall curves for each class. Defaults to False.\n",
      "        on_plot (func): An optional callback to pass plots path and data when they are rendered. Defaults to None.\n",
      "        names (dict of str): A dict of strings that represents the names of the classes. Defaults to an empty tuple.\n",
      "\n",
      "    Attributes:\n",
      "        save_dir (Path): A path to the directory where the output plots will be saved.\n",
      "        plot (bool): A flag that indicates whether to plot the precision-recall curves for each class.\n",
      "        on_plot (func): An optional callback to pass plots path and data when they are rendered.\n",
      "        names (dict of str): A dict of strings that represents the names of the classes.\n",
      "        box (Metric): An instance of the Metric class for storing the results of the detection metrics.\n",
      "        speed (dict): A dictionary for storing the execution time of different parts of the detection process.\n",
      "\n",
      "    Methods:\n",
      "        process(tp, conf, pred_cls, target_cls): Updates the metric results with the latest batch of predictions.\n",
      "        keys: Returns a list of keys for accessing the computed detection metrics.\n",
      "        mean_results: Returns a list of mean values for the computed detection metrics.\n",
      "        class_result(i): Returns a list of values for the computed detection metrics for a specific class.\n",
      "        maps: Returns a dictionary of mean average precision (mAP) values for different IoU thresholds.\n",
      "        fitness: Computes the fitness score based on the computed detection metrics.\n",
      "        ap_class_index: Returns a list of class indices sorted by their average precision (AP) values.\n",
      "        results_dict: Returns a dictionary that maps detection metric keys to their computed values.\n",
      "        curves: TODO\n",
      "        curves_results: TODO\n",
      "    \n",
      "2024-11-20 05:10:53,835 - ERROR - Error during training with 3000 boxes: 'list' object is not callable\n",
      "2024-11-20 05:10:53,837 - INFO - All training complete!\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds\n",
    "    set_all_seeds()\n",
    "    \n",
    "    # Initialize paths and parameters\n",
    "    image_dir = r'E:\\Data 255\\YOLO multi-class\\image_data\\training_images_10_class'\n",
    "    project_dir = r'E:\\Data 255\\YOLO multi-class\\yolo_training'\n",
    "    class_desc_path = 'oidv7-class-descriptions-boxable.csv'\n",
    "    annotations_path = 'oidv6-train-annotations-bbox.csv'\n",
    "    \n",
    "    # Create project directory\n",
    "    os.makedirs(project_dir, exist_ok=True)\n",
    "    \n",
    "    # Initialize class loader with image directory\n",
    "    class_loader = MultiClassDataLoader(class_desc_path, annotations_path, image_dir)\n",
    "    \n",
    "    # Training parameters\n",
    "    bounding_box_counts = [3000]  # Boxes per class\n",
    "    fixed_val_size = 500  # Validation boxes per class\n",
    "    \n",
    "    # Train models\n",
    "    results = []\n",
    "    for box_count in bounding_box_counts:\n",
    "        try:\n",
    "            metrics = train_multi_class_yolo(\n",
    "                box_count,\n",
    "                image_dir,\n",
    "                project_dir,\n",
    "                class_loader,\n",
    "                fixed_val_size\n",
    "            )\n",
    "            if metrics:\n",
    "                results.append(metrics)\n",
    "                save_results(results, project_dir)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during training with {box_count} boxes: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    logging.info(\"All training complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
